 1. New methodological improvements to self-supervised learning in computer vision.
    - Relevant: papers that propose new self-supervised approaches for images, aiming to improve existing methods, or analyzing them. Usually these papers will mention a pretext task used to pretrain the neural networks resulting in higher performance when fine-tuing on the down-stream tasks.
    - Not relevant: papers that apply existing self-supervised learning to computer vision tasks in the specific field, such as medical images, remote sensing, pedestrian re-identification and so on.

 In suggesting papers to your friend, remember that he enjoys papers on statistical machine learning, and generative modeling in natural language processing.
 Your friend also likes learning about surprising empirical results in language models, as well as clever statistical tricks.
 He does not want to read papers that are about primarily applications of methods to specific domains.
