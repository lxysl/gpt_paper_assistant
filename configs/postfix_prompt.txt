Write the response in JSONL format with {ARXIVID, COMMENT, RELEVANCE, NOVELTY, TLDR} on each line, one for each paper. The meaning and requirements of each item are introduced as follows.

---

- The ARXIVID should be the ArXiv ID.
- The COMMENT should identify whether there is a criteria that match the paper very closely.
    > If so, it MUST start with "Criterion: N" where N is the number of the matching criterion (e.g., "Criterion: 8" for criterion 8).
    > If there are multiple matching criteria, list them as "Criterion: N, M" (e.g., "Criterion: 2, 5").
    > If not necessary, try to assign only the most precise criterion, such as choosing the smaller field when two criterions overlap.
    > If no specific criterion matches, start with "Criterion: 0" and then provide your comment.
    > These matches should not be based on general terms like "language modeling" or "advancements" and should specifically refer to a criterion.
    > Do NOT output any content other than "Criterion: N".
- The RELEVANCE should be a relevance score from 1-10 where:
    > 10: EXTREMELY RARE - Only for papers that are PERFECTLY aligned with a specific criterion, use EXACT terminology from the criterion, AND have authors who are widely recognized as TOP experts in that exact area. This should be given to less than 5% of papers.
    > 9: Excellent match - Very closely matches a specific criterion with precise terminology and methodology, with strong author credentials in the field.
    > 8: Good match - Clearly matches a specific criterion with appropriate technical approach and relevant author background.
    > 7: Solid match - Matches a criterion well but may lack some precision in approach or author expertise.
    > 6: Decent match - Relates to a criterion but with some gaps in alignment or methodology.
    > 5: Moderate match - Generally relates to a criterion but not specifically targeted.
    > 4: Weak relation - Tangentially related to interest areas but doesn't match specific criteria.
    > 3: General area relevance - In the broad field of interest but not addressing specific criteria.
    > 2: Distant relation - Loosely connected to the field.
    > 1: Irrelevant - No meaningful connection to any criteria or interest areas.
- The NOVELTY should be a score from 1 to 10, where:
    > 10: REVOLUTIONARY - Less than 1% of papers. Introduces fundamentally new paradigms that will reshape multiple research directions. Think GPT-1, ResNet, or Transformer-level breakthroughs.
    > 9: Groundbreaking - Introduces significant new concepts with broad impact potential.
    > 8: Highly novel - Presents substantial innovations with clear advances over existing work.
    > 7: Novel - Introduces meaningful new ideas or significant improvements.
    > 6: Moderately novel - Some new ideas but mostly incremental improvements.
    > 5: Incremental - Reasonable improvements over existing methods.
    > 4: Minor novelty - Small improvements or new applications.
    > 3: Limited novelty - Mostly known techniques with minor variations.
    > 2: Very limited - Primarily reproduces or slightly modifies existing work.
    > 1: No novelty - Pure reproduction or trivial modifications.
- The TLDR should be a concise and impactful Chinese sentence within "ONE paragraph", enabling researchers to quickly determine "whether it's worth clicking into.". It should follow these 12 rules:
    > 1.	开头写论文提出的方法名，后跟中文全角冒号“：”。若无方法名称并且标题太长可直接略去。
    > 2.	一句话点明研究对象与核心创新（例如「一种 XXX 方法」「首个 XXX 框架」）。
    > 3.	紧接着用 1‑3 个短分句归纳 关键技术/策略/模块，不要展开原理，只给关键词。
    > 4.	若摘要中出现速度、参数量、内存、训练成本等数字 → 直接引用并加“×”“%”等单位，突出效率/规模优势。
    > 5.	若出现 指标或数据集 → 说明「在 XXX 数据集上以 FID=5.1 / mAP=76.2 达到 SOTA」。
    > 6.	如果摘要或作者页明确提到 开源 / 代码链接 / 预训练权重 → 加一句「代码已开源」。
    > 7.    如果是提出数据集、评测榜单的论文，或者综述论文，则列出其内容特色。
    > 8.	若作者为本领域内具有一定影响力的学者（如何恺明等），请在最后附上其姓名，表明其参与了该研究。
    > 9.	使用中文回复，整段控制在 100‑200 个汉字（含标点），保持 新闻标题式节奏；允许使用 ！ 强调亮点，不要空行、不要列表。
    > 10.	不要复述原文句子；不得输出除这一段以外的额外内容。
    > 11.	如遇摘要缺少关键信息，可省略对应要素，切勿编造。
    > 12.   使用标准 json 格式输出，不要输出其他内容。

---

- ** CRITICAL FINAL OUTPUT REQUIREMENTS: **
    > OUTPUT ONLY VALID JSONL FORMAT - one JSON object per line for each paper
    > DO NOT include any explanations, comments, or additional text before or after the JSONL output
    > DO NOT explain your scoring decisions or reasoning
    > Each line must be a complete, valid JSON object with exactly these fields: {ARXIVID, COMMENT, RELEVANCE, NOVELTY, TLDR}
    > Be VERY conservative with scores 9-10 for the RELEVANCE and NOVELTY metrics. Most good papers should receive scores in the 5-7 range.